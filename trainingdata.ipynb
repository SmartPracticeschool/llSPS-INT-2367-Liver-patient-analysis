{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# for dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# for easier visualization\n",
    "import seaborn as sns\n",
    "\n",
    "# for visualization and to display plots\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import color maps\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "# to split train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to perform hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import accuracy_score\n",
    "#import xgboost\n",
    "import os\n",
    "mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-7.2.0-posix-seh-rt_v5-rev0\\\\mingw64\\\\bin'\n",
    "os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\samsung\\\\Desktop\\\\LIVERPATIENTANALYSIS'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\samsung\\\\Desktop\\\\LIVERPATIENTANALYSIS'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"C:/Users/samsung/Desktop/LIVERPATIENTANALYSIS\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"liver_patient_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Total_Bilirubin</th>\n",
       "      <th>Direct_Bilirubin</th>\n",
       "      <th>Alkaline_Phosphotase</th>\n",
       "      <th>Alamine_Aminotransferase</th>\n",
       "      <th>Aspartate_Aminotransferase</th>\n",
       "      <th>Total_Protiens</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Albumin_and_Globulin_Ratio</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>Male</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>Male</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>34</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.37</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>40</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>98</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>52</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>245</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>31</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>184</td>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>38</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>216</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>583 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Gender  Total_Bilirubin  Direct_Bilirubin  Alkaline_Phosphotase  \\\n",
       "0     65  Female              0.7               0.1                   187   \n",
       "1     62    Male             10.9               5.5                   699   \n",
       "2     62    Male              7.3               4.1                   490   \n",
       "3     58    Male              1.0               0.4                   182   \n",
       "4     72    Male              3.9               2.0                   195   \n",
       "..   ...     ...              ...               ...                   ...   \n",
       "578   60    Male              0.5               0.1                   500   \n",
       "579   40    Male              0.6               0.1                    98   \n",
       "580   52    Male              0.8               0.2                   245   \n",
       "581   31    Male              1.3               0.5                   184   \n",
       "582   38    Male              1.0               0.3                   216   \n",
       "\n",
       "     Alamine_Aminotransferase  Aspartate_Aminotransferase  Total_Protiens  \\\n",
       "0                          16                          18             6.8   \n",
       "1                          64                         100             7.5   \n",
       "2                          60                          68             7.0   \n",
       "3                          14                          20             6.8   \n",
       "4                          27                          59             7.3   \n",
       "..                        ...                         ...             ...   \n",
       "578                        20                          34             5.9   \n",
       "579                        35                          31             6.0   \n",
       "580                        48                          49             6.4   \n",
       "581                        29                          32             6.8   \n",
       "582                        21                          24             7.3   \n",
       "\n",
       "     Albumin  Albumin_and_Globulin_Ratio  Dataset  \n",
       "0        3.3                        0.90        1  \n",
       "1        3.2                        0.74        1  \n",
       "2        3.3                        0.89        1  \n",
       "3        3.4                        1.00        1  \n",
       "4        2.4                        0.40        1  \n",
       "..       ...                         ...      ...  \n",
       "578      1.6                        0.37        2  \n",
       "579      3.2                        1.10        1  \n",
       "580      3.2                        1.00        1  \n",
       "581      3.4                        1.00        1  \n",
       "582      4.4                        1.50        2  \n",
       "\n",
       "[583 rows x 11 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing \n",
    "\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "\n",
    "# Encode labels in column 'species'. \n",
    "df['Gender']= label_encoder.fit_transform(df['Gender']) \n",
    "\n",
    "df['Gender'].unique() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Total_Bilirubin</th>\n",
       "      <th>Direct_Bilirubin</th>\n",
       "      <th>Alkaline_Phosphotase</th>\n",
       "      <th>Alamine_Aminotransferase</th>\n",
       "      <th>Aspartate_Aminotransferase</th>\n",
       "      <th>Total_Protiens</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Albumin_and_Globulin_Ratio</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>34</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.37</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>98</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>245</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>184</td>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>216</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>583 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Gender  Total_Bilirubin  Direct_Bilirubin  Alkaline_Phosphotase  \\\n",
       "0     65       0              0.7               0.1                   187   \n",
       "1     62       1             10.9               5.5                   699   \n",
       "2     62       1              7.3               4.1                   490   \n",
       "3     58       1              1.0               0.4                   182   \n",
       "4     72       1              3.9               2.0                   195   \n",
       "..   ...     ...              ...               ...                   ...   \n",
       "578   60       1              0.5               0.1                   500   \n",
       "579   40       1              0.6               0.1                    98   \n",
       "580   52       1              0.8               0.2                   245   \n",
       "581   31       1              1.3               0.5                   184   \n",
       "582   38       1              1.0               0.3                   216   \n",
       "\n",
       "     Alamine_Aminotransferase  Aspartate_Aminotransferase  Total_Protiens  \\\n",
       "0                          16                          18             6.8   \n",
       "1                          64                         100             7.5   \n",
       "2                          60                          68             7.0   \n",
       "3                          14                          20             6.8   \n",
       "4                          27                          59             7.3   \n",
       "..                        ...                         ...             ...   \n",
       "578                        20                          34             5.9   \n",
       "579                        35                          31             6.0   \n",
       "580                        48                          49             6.4   \n",
       "581                        29                          32             6.8   \n",
       "582                        21                          24             7.3   \n",
       "\n",
       "     Albumin  Albumin_and_Globulin_Ratio  Dataset  \n",
       "0        3.3                        0.90        1  \n",
       "1        3.2                        0.74        1  \n",
       "2        3.3                        0.89        1  \n",
       "3        3.4                        1.00        1  \n",
       "4        2.4                        0.40        1  \n",
       "..       ...                         ...      ...  \n",
       "578      1.6                        0.37        2  \n",
       "579      3.2                        1.10        1  \n",
       "580      3.2                        1.00        1  \n",
       "581      3.4                        1.00        1  \n",
       "582      4.4                        1.50        2  \n",
       "\n",
       "[583 rows x 11 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "8    0\n",
       "9    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer \n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(X[:,[9]])\n",
    "X[:,[9]]=imputer.fit_transform(X[:,[9]])\n",
    "df1=pd.DataFrame(X)\n",
    "df1.apply(lambda X:sum(X.isnull()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1,\n",
       "       2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 2,\n",
       "       2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1,\n",
       "       2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1,\n",
       "       1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
       "       2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1,\n",
       "       1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 1, 1,\n",
       "       1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2,\n",
       "       1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1,\n",
       "       1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2,\n",
       "       2, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "       1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2,\n",
       "       1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1,\n",
       "       1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2,\n",
       "       1, 1, 1, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1,\n",
       "       1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=1234,\n",
    "                                                    stratify=df.Dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(466, 10) (117, 10) (466,) (117,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = X_train.mean()\n",
    "train_std = X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Score: \n",
      " 72.1\n",
      "Neural Test Score: \n",
      " 70.94\n",
      "Accuracy: \n",
      " 0.7094017094017094\n",
      "[[83 34]\n",
      " [ 0  0]]\n"
     ]
    }
   ],
   "source": [
    "neural = MLPClassifier(hidden_layer_sizes=40,\n",
    "                     activation='relu',\n",
    "                     solver='adam',\n",
    "                     alpha=0.001,\n",
    "                     batch_size='auto',\n",
    "                     max_iter=200,\n",
    "                     random_state=137,\n",
    "                     tol=0.0001,\n",
    "                     early_stopping=False,\n",
    "                     validation_fraction=0.1,\n",
    "                     beta_1=0.9,\n",
    "                     beta_2=0.999,\n",
    "                     epsilon=1e-08,\n",
    "                     learning_rate='constant',\n",
    "                     power_t=0.5,\n",
    "                     momentum=0.8,\n",
    "                     nesterovs_momentum=True,\n",
    "                     shuffle=True,\n",
    "                     learning_rate_init=0.001)\n",
    "neural.fit(X_train, y_train)\n",
    "#Predict Output\n",
    "predicted = neural.predict(X_test)\n",
    "\n",
    "neural_score = round(neural.score(X_train, y_train) * 100, 2)\n",
    "neural_score_test = round(neural.score(X_test, y_test) * 100, 2)\n",
    "print('Neural Score: \\n', neural_score)\n",
    "print('Neural Test Score: \\n', neural_score_test)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, predicted))\n",
    "print(confusion_matrix(predicted,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = neural.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5248255774571564"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train,y_train_pred )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal number of neighbors is 11.\n"
     ]
    }
   ],
   "source": [
    "# creating odd list of K for KNN\n",
    "neighbors = list(range(1,20,2))\n",
    "# empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "\n",
    "#  10-fold cross validation , 9 datapoints will be considered for training and 1 for cross validation (turn by turn) to determine value of k\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())   \n",
    "\n",
    "# changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "# determining best k\n",
    "optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal number of neighbors is %d.' % optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE.index(min(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot misclassification error vs k \n",
    "plt.plot(neighbors, MSE)\n",
    "plt.xlabel('Number of Neighbors K')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=11, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors = optimal_k)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6316353947932896"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "def svc_param_selection(X, y, nfolds):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "    grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=nfolds)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svClassifier=SVC(kernel='rbf',probability=True)\n",
    "svClassifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.001, 'gamma': 0.001}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_param_selection(X_train,y_train,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
       "    probability=False, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Building the model again with the best hyperparameters\n",
    "model = SVC(C=1, gamma=1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
